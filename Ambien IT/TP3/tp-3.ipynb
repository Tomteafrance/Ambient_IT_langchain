{"cells":[{"cell_type":"markdown","metadata":{"id":"Ilc7xsEr5rbc"},"source":["# Cours LangChain TP3"]},{"cell_type":"markdown","metadata":{"id":"uFEL87af5rbe"},"source":["Dans ce TP vous allez apprendre à executer et utiliser plusieurs chaines en parallèles et aussi à apprendre à utiliser le modules de mémoire de LangChain"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RG_8CPPV5rbe","executionInfo":{"status":"ok","timestamp":1710234303114,"user_tz":-60,"elapsed":14072,"user":{"displayName":"Tom TEA","userId":"00599091751588244729"}},"outputId":"104c96e9-df12-4804-bbf9-2fa708b9a802"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install --quiet -U langchain-openai langchain docarray tiktoken faiss-gpu\n","import os\n","os.environ['OPENAI_API_KEY']=\"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\" # À Modifier"]},{"cell_type":"markdown","metadata":{"id":"p3HupN2G5rbf"},"source":["# Tâche Chaînes en séries et en parallèles"]},{"cell_type":"markdown","metadata":{"id":"et0nKUqd5rbg"},"source":["Continuons avec l'exemple du TP 2 où nous avions créer une chaine pour récuperer du contexte sur une histoire d'un document texte\n","Créons plusieurs chaines pour écrire une histoire à suspens avec un retournement de situation et un conclusion."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ORB5vcNo5rbg","executionInfo":{"status":"ok","timestamp":1710234307690,"user_tz":-60,"elapsed":892,"user":{"displayName":"Tom TEA","userId":"00599091751588244729"}}},"outputs":[],"source":["#Solution du TP 2\n","from langchain_community.document_loaders import TextLoader\n","from langchain_community.vectorstores import FAISS\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_openai import OpenAIEmbeddings\n","from langchain_text_splitters import CharacterTextSplitter\n","from langchain_openai import ChatOpenAI\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n","\n","documents = TextLoader(\"document.txt\").load()\n","text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n","docs = text_splitter.split_documents(documents)\n","\n","embeddings = OpenAIEmbeddings()\n","\n","db = FAISS.from_documents(docs, embeddings)\n","\n","retriever = db.as_retriever()\n","\n","model = ChatOpenAI()\n","output_parser = StrOutputParser()"]},{"cell_type":"markdown","metadata":{"id":"X-Yp2NDQ5rbg"},"source":["## Exercice 1\n","\n","### A. Ecrivez 3 chaines en séries à partir des prompts ci dessous:\n","* Une qui reprend le texte en tant que retriever et un titre à la suite de l'histoire\n","* Une chaine qui écrit le plot twist de la suite\n","* une chaine qui en fonction de ce plot twist ecrira une fin heureuse à cette histoire\n","\n","Faites run ces chaines en séries"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"dRnEevHB5rbg","executionInfo":{"status":"ok","timestamp":1710234360128,"user_tz":-60,"elapsed":389,"user":{"displayName":"Tom TEA","userId":"00599091751588244729"}}},"outputs":[],"source":["prompt1 = ChatPromptTemplate.from_template(\n","    \"À partir du contexte {context} continue l'histoire en rajoutant un évenement qui va boulverser notre personnage principal. Le titre de l'histoire sera {titre}\"\n","    )\n","prompt2 = ChatPromptTemplate.from_template(\n","    \"À partir du bout de l'histoire '{boulversement}',écriver l'histoire en continuant sur un retournement de situation qui mettra notre personnage principal.\"\n","    )\n","prompt3 = ChatPromptTemplate.from_template(\n","        \"À partir du bout de l'histoire '{plot_twist}',écriver l'histoire en continuant sur une fin heureuse à cette histoire.\"\n","    )"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"pY8ponjX5rbh","executionInfo":{"status":"ok","timestamp":1710235933564,"user_tz":-60,"elapsed":2,"user":{"displayName":"Tom TEA","userId":"00599091751588244729"}}},"outputs":[],"source":["model_parser = model | StrOutputParser()\n","\n","setup_and_retrieval = RunnableParallel(\n","    {\"context\": retriever, \"titre\": RunnablePassthrough()}\n",")\n","\n","boulversement_chain = ({\"context\": retriever, \"titre\": RunnablePassthrough()} | prompt1 | {\"boulversement\": model_parser})\n","plot_chain = prompt2 | model_parser\n","fin_chain = prompt3 | model_parser\n","chain = (boulversement_chain |{\"plot_twist\": plot_chain} | fin_chain)\n"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"hNIVfUnT5rbh","executionInfo":{"status":"ok","timestamp":1710235953871,"user_tz":-60,"elapsed":19588,"user":{"displayName":"Tom TEA","userId":"00599091751588244729"}}},"outputs":[],"source":["from pprint import pprint\n","result = chain.invoke(\"Les aventures bizarres d'Aaron\")"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y7hOb1SW5rbh","executionInfo":{"status":"ok","timestamp":1710235959171,"user_tz":-60,"elapsed":340,"user":{"displayName":"Tom TEA","userId":"00599091751588244729"}},"outputId":"8eb4686b-2e19-4785-a5fa-6d049466155f"},"outputs":[{"output_type":"stream","name":"stdout","text":["(\"Après l'arrestation de James, Aaron se sentit soulagé d'avoir pris la bonne \"\n"," 'décision, même si cela signifiait mettre son propre frère derrière les '\n"," 'barreaux. Sa famille, bien que choquée par la révélation, le soutint dans sa '\n"," 'décision et lui assura de leur amour et de leur soutien.\\n'\n"," '\\n'\n"," 'Avec cette affaire résolue, Aaron reprit ses activités de détective privé '\n"," 'avec une détermination renouvelée. Il se plongea dans de nouvelles affaires '\n"," 'mystérieuses, résolvant des énigmes complexes et rendant justice aux '\n"," 'victimes. Sa réputation grandissait et il était de plus en plus sollicité '\n"," 'pour résoudre des cas difficiles.\\n'\n"," '\\n'\n"," \"Malgré les épreuves qu'il avait traversées, Aaron trouva une nouvelle \"\n"," 'énergie et un nouveau sens à sa vie. Il réalisa que la vérité était parfois '\n"," \"difficile à accepter, mais qu'elle était toujours préférable à l'ignorance. \"\n"," \"Il était fier d'avoir pris la bonne décision, même si cela avait été \"\n"," 'difficile.\\n'\n"," '\\n'\n"," \"La vie d'Aaron reprit son cours, avec de nouveaux défis à relever et de \"\n"," \"nouvelles aventures à vivre. Il savait désormais qu'il pouvait faire \"\n"," 'confiance à son instinct et à sa détermination pour faire face à tout ce qui '\n"," \"se présentait sur son chemin. Et il était prêt à affronter l'avenir avec \"\n"," \"courage et détermination, sachant qu'il était capable de surmonter tous les \"\n"," 'obstacles qui se dressaient devant lui.')\n"]}],"source":["pprint(result)"]},{"cell_type":"markdown","metadata":{"id":"ngW4_Qqx5rbi"},"source":["## Exercice 2"]},{"cell_type":"markdown","metadata":{"id":"v59tCuPW5rbi"},"source":["Ecrivez 3 chaines en parallèles à partir des prompts ci dessous:\n","* Une qui reprend le texte en tant que retriever et qui compte le nombre de fois que le mot `{mot}` apparaît\n","* Une chaine qui rajouterai un personnage à l'Histoire\n","* une chaine qui rajouerait une phrase (rien à voir) avec le `{mot}` en paramètre"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"6-zySSe-5rbi","executionInfo":{"status":"ok","timestamp":1710237177757,"user_tz":-60,"elapsed":1061,"user":{"displayName":"Tom TEA","userId":"00599091751588244729"}}},"outputs":[],"source":["from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.runnables import RunnableParallel, RunnableSequence\n","from langchain_openai import ChatOpenAI\n","from operator import itemgetter\n","\n","setup_and_retrieval = RunnableParallel(\n","    {\"context\": retriever, \"mot\": RunnablePassthrough()}\n",")\n","\n","#Faire les prompts\n","prompt1 = ChatPromptTemplate.from_template(\n","    \"À partir du contexte {context} compte le nombre de {mot} qui apparaît dans le texte\"\n","    )\n","\n","prompt2 = ChatPromptTemplate.from_template(\n","    \"À partir du contexte {context} , rajoute un personnage à l'histoire.\"\n","    )\n","prompt3 = ChatPromptTemplate.from_template(\n","    \"Rajoutes une phrase qui n'a rien à voir avec le {mot}.\"\n","    )\n","\n","model = ChatOpenAI()\n","\n","\n","# Voir la correction - chain plus simple à faire\n","#declarer les chaines\n","planner = (\n","    ChatPromptTemplate.from_template(\"Génère-moi une histoire sur: {input}\")\n","    | ChatOpenAI()\n","    | StrOutputParser()\n","    | {\"base_response\": RunnablePassthrough()}\n",")\n","\n","count_word = (\n","    ChatPromptTemplate.from_template(\n","        \"À partir du contexte compte le nombre de {mot} qui apparaît dans le {base_response}\"\n","    )\n","    | ChatOpenAI()\n","    | StrOutputParser()\n",")\n","add_person = (\n","    ChatPromptTemplate.from_template(\n","        \"Rajoute un personnage à l'histoire: {base_response}\"\n","    )\n","    | ChatOpenAI()\n","    | StrOutputParser()\n",")\n","\n","add_sentence = (\n","    ChatPromptTemplate.from_template(\n","        \"Rajoute une phrase qui n'a rien à voir avec l'histoire: {base_response}\"\n","    )\n","    | ChatOpenAI()\n","    | StrOutputParser()\n",")\n","\n","final_responder = (\n","    ChatPromptTemplate.from_messages(\n","        [\n","            (\"ai\", \"{original_response}\"),\n","            (\"human\", \"Pros:\\n{results_1}\\n\\nCons:\\n{results_2}\"),\n","            (\"system\", \"Génère une conclusion en fonction de la critique reçu\"),\n","        ]\n","    )\n","    | ChatOpenAI()\n","    | StrOutputParser()\n",")\n","\n","\n","#les mettre en parallèles\n","chain = (\n","    planner\n","    | {\n","        \"count_word\": count_word,\n","        \"add_person\": add_person,\n","        \"add_sentence\": add_sentence,\n","        \"original_response\": itemgetter(\"base_response\"),\n","    }\n","    | final_responder\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"Lhg33rPO5rbi"},"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}